{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6bb9b-c813-439a-b261-716c94825430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "IMAGE_ORDERING = 'channels_last'\n",
    "tf.executing_eagerly()\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfaffe-2686-43e2-9fe8-0ca56467b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "data_test=np.load(\"Covariate_grid2_final.npy\")\n",
    "Y_sus=np.load(\"Label_grid2_final.npy\")[:,:,:,2]\n",
    "Y_sus[Y_sus>0]=1\n",
    "labels_test=Y_sus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a752e00-6cbc-4a26-977c-57df47f99b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c9569-852f-4107-9a6a-1ddfb91ae3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindata=data_test.min(axis=(0,1,2))\n",
    "maxdata=data_test.max(axis=(0,1,2))\n",
    "data_test=(data_test-mindata)/(maxdata-mindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23736823-ecf0-47b4-815e-4cab12a8c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata=np.load(\"Covariate_grid1_final.npy\")\n",
    "Y_sus=np.load(\"Label_grid1_final.npy\")[:,:,:,:2]\n",
    "# Y_area=np.load(\"labels_area_density.npy\")\n",
    "#normalizer.adapt(Xdata)\n",
    "Ydata=np.expand_dims(np.argmax(Y_sus,axis=-1),axis=-1)\n",
    "mindata=Xdata.min(axis=(0,1,2))\n",
    "maxdata=Xdata.max(axis=(0,1,2))\n",
    "Xdata=(Xdata-mindata)/(maxdata-mindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319a1aa-679c-4d6a-b53c-0d3d4c26c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with\n",
    "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "def one_side_pad(x):\n",
    "    x = ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING)(x)\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        x = Lambda(lambda x: x[:, :, :-1, :-1])(x)\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        x = Lambda(lambda x: x[:, :-1, :-1, :])(x)\n",
    "    return x\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def regression_block(input_tensor,o1_tensor):\n",
    "    \n",
    "    y = LandslideArea(1024)(input_tensor,o1_tensor)\n",
    "    y = LandslideArea(512)(y,o1_tensor)\n",
    "    y = LandslideArea(256)(y,o1_tensor)\n",
    "    y = LandslideArea(128)(y,o1_tensor)\n",
    "    y = LandslideArea(64)(y,o1_tensor)\n",
    "    y = LandslideArea(32)(y,o1_tensor)\n",
    "    y = LandslideArea(16)(y,o1_tensor)\n",
    "    y = LandslideArea(1)(y,o1_tensor)\n",
    "    return y\n",
    "    \n",
    "def get_resnet50_unet(n_classes=2,input_height=128,  input_width=128, channels=11):\n",
    "\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "    \n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        img_input = Input(shape=(channels, input_height, input_width))\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        img_input = Input(shape=(input_height, input_width, channels))\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    if IMAGE_ORDERING == 'channels_first':\n",
    "        MERGE_AXIS = 1\n",
    "    elif IMAGE_ORDERING == 'channels_last':\n",
    "        MERGE_AXIS = -1\n",
    "    l1_skip_conn=True\n",
    "    #x = normalizer()\n",
    "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (4, 4), data_format=IMAGE_ORDERING,\n",
    "               strides=(2, 2), name='conv1')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    br1=tf.identity(x,name='branch_1')\n",
    "    br1=AveragePooling2D((2, 2), padding='same')(br1)\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    # classification part\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(x)\n",
    "    x = (Conv2D(1, (3, 3), padding='valid' , activation='relu' , data_format=IMAGE_ORDERING))(x)\n",
    "    x = (BatchNormalization())(x)\n",
    "    o1=Activation(activation=\"sigmoid\",name=\"sus_output\")(x)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=[img_input], outputs=[o1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713ad02-b5e8-40fb-a94a-8772db6c247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_resnet50_unet(n_classes=1,input_height=128,  input_width=128, channels=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277cd7f-29d6-4402-b38f-0d9dec61cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='Susceptibilitypart.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6739a-8707-4943-90fa-7a875e3a14e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"checkpoint_classification_V2.4\") #load initial weights because training is done in multiple stages, you need to load previous state\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75a0b6-25fa-4c59-9af4-0df8328f67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=20000,decay_rate=0.9)\n",
    "import keras.backend as K\n",
    "\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "def recall(targets, inputs):\n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    targets = K.cast(targets, dtype='float32')\n",
    "    #print(targets)\n",
    "    #True Positives, False Positives & False Negatives\n",
    "    TP = K.sum((inputs * targets))\n",
    "    FP = K.sum(((1-targets) * inputs))\n",
    "    FN = K.sum((targets * (1-inputs)))\n",
    "            \n",
    "    return (TP/(TP+FN+1e-7))\n",
    "\n",
    "def precision(targets, inputs):\n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    targets = K.cast(targets, dtype='float32')\n",
    "    \n",
    "    #True Positives, False Positives & False Negatives\n",
    "    TP = K.sum((inputs * targets))\n",
    "    FP = K.sum(((1-targets) * inputs))\n",
    "    FN = K.sum((targets * (1-inputs)))\n",
    "    return (TP/(TP+FP+1e-7))\n",
    "\n",
    "def f1_score(targets, inputs):\n",
    "    p = precision(targets, inputs)\n",
    "    r = recall(targets, inputs)\n",
    "    return 2*((p*r)/(p+r+1e-6))\n",
    "\n",
    "ALPHA = 0.30\n",
    "BETA = 0.70\n",
    "GAMMA = 1\n",
    "def FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        targets = K.cast(targets, dtype='float32')\n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky   \n",
    "def regressionloss(y_true, y_pred):\n",
    "    y_true_flat=K.flatten(y_true)\n",
    "    y_pred_flat=K.flatten(y_pred)\n",
    "    mask=tf.where(y_true_flat==0.,False,True)\n",
    "    y=tf.boolean_mask(y_true_flat, mask)\n",
    "    ypred=tf.boolean_mask(y_pred_flat, mask)\n",
    "    #print(y,ypred)\n",
    "    pixel_sq_loss=FocalTverskyLoss    \n",
    "    loss_val=pixel_sq_loss(y,ypred)\n",
    "    return tf.reduce_mean(loss_val)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "              metrics=[ f1_score,tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.AUC(),tf.keras.metrics.FalseNegatives(),tf.keras.metrics.FalsePositives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304b923-ac97-4a59-bd8a-5d687c1de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_EPOCHS = 100\n",
    "filepath=\"checkpoint_classification_V2.4\"\n",
    "model_checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor=\"f1_score\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"max\",\n",
    "    save_freq=\"epoch\",\n",
    "    options=None\n",
    ")\n",
    "import os,datetime\n",
    "logdir = os.path.join(\"logs_classification\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "\n",
    "def train(model, xdata,ydata):\n",
    "    hist = model.fit(x=xdata,\n",
    "                     y=ydata,\n",
    "                     epochs=NUMBER_EPOCHS,\n",
    "                     validation_split=0.0,\n",
    "                     batch_size=4,#auto validate using 30% of random samples at each epoch\n",
    "                     verbose=1, callbacks=[model_checkpoint_callback,tensorboard_callback] ,sample_weight=zeros\n",
    "                    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471705bd-3a20-4e92-af6d-ea0284b41604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# data_train, data_test, labels_train, labels_test = train_test_split(Xdata[10680:], Ydata[10680:], test_size=0.30, random_state=42)\n",
    "# labels_test=np.rot90(labels_test,axes=(1,2))\n",
    "# data_test=np.rot90(data_test,axes=(1,2))\n",
    "# labels_train=np.rot90(labels_train,axes=(1,2))\n",
    "# data_train=np.rot90(data_train,axes=(1,2))\n",
    "zeros=np.zeros(labels_test.shape)\n",
    "zeros[labels_test==[0.]]=1\n",
    "zeros[labels_test==[1.]]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8ea2e-4523-4a43-8615-f287d7cb2326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=train(model,Xdata,np.expand_dims(Ydata,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446309e-65d0-411f-9c80-d79e78531754",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ydata_pred_s=model.predict(data_test,batch_size=16)\n",
    "f1_score(labels_test.flatten(),np.rint(Ydata_pred_s.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b06a3-b5de-403f-98db-8db615cf4285",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels_test.flatten(),np.rint(Ydata_pred_s.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff41b4-97df-4473-a35f-720b1734a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(6, 6), dpi=500)\n",
    "preds = Ydata_pred_s.flatten()\n",
    "fpr, tpr, threshold = metrics.roc_curve(labels_test.flatten(),preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "\n",
    "plt.title('ROC Susceptibility')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('ROC.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
